# Group-15.DSB2023
After accessing the card_fraud.csv data, we used some of the Exploratory data analysis instruments to analyze the variables in the dataset: with the correlation matrix we assessed the correlation between all possible combinations of variables, with ggplot we visualized the trends connecting two or more sets of variables, and with the creation of tables we summarized the statistical values of the variables. We also assessed the distribution of the numerical variables to use in the prediction model and analyzes the outliers. 

Having analyzed and adjusted the dataset, we selected the relevant variables for our model, that consisted in two iterations. We started with a smaller dataset (10% of the entire data frame), creating a first recipe and five models. In the recipe, all merchant categories under 5% and all job categories under 0.1%  fall under “others”; the city population variable is changed to log scale and the nominal variables are converted into numeric dummy variables. The five models are:  logistic regression, decision tree, random forest, boosted tree and a k-nearest neighbor. We fitted each of the models. 
With the second iteration we chose the best performing model, we reorganized it into an increased number of folds 8from 3 to 10) and then we runned the last fit on the entire dataset, using the best model.
